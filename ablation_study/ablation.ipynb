{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ablation Study: RL Agents for Fraud Detection\n",
    "\n",
    "This notebook performs an ablation study to compare the performance of different Reinforcement Learning (RL) agents (PPO, A2C, DQN) on two fraud detection datasets (CreditCard and PaySim). \n",
    "We also evaluate the impact of different preprocessing techniques: Raw Data, PCA, and CTGAN Data Augmentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fcfdd72ae10>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gymnasium as gym\n",
    "from gymnasium import spaces\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "from stable_baselines3 import PPO, A2C, DQN\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "from ctgan import CTGAN\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "\n",
    "# Define a learning rate schedule\n",
    "def linear_schedule(initial_value):\n",
    "    def schedule(progress_remaining):\n",
    "        return progress_remaining * initial_value\n",
    "    return schedule\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Custom RL Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FraudDetectionEnv(gym.Env):\n",
    "    \"\"\"\n",
    "    A custom Gym environment for Fraud Detection.\n",
    "    State: Feature vector of a transaction.\n",
    "    Action: 0 (Declare Not Fraud), 1 (Declare Fraud).\n",
    "    Reward: Based on correctly/incorrectly classifying fraud vs non-fraud.\n",
    "    \"\"\"\n",
    "    def __init__(self, features: np.ndarray, labels: np.ndarray, reward_config: dict = None):\n",
    "        super().__init__()\n",
    "        \n",
    "        if reward_config is None:\n",
    "            # Default reward configuration favoring recall of fraud\n",
    "            self.reward_config = {\n",
    "    'TP': 10.0,\n",
    "    'FP': -5.0,\n",
    "    'FN': -20.0,\n",
    "    'TN': 1.0\n",
    "}\n",
    "\n",
    "        else:\n",
    "            self.reward_config = reward_config\n",
    "\n",
    "        self.features = features.astype(np.float32)\n",
    "        self.labels = labels.astype(np.int64)\n",
    "\n",
    "        self.num_instances = self.features.shape[0]\n",
    "        self.feature_dim = self.features.shape[1]\n",
    "\n",
    "        # Action Space: Discrete(2) -> 0 for Not Fraud, 1 for Fraud\n",
    "        self.action_space = spaces.Discrete(2)\n",
    "\n",
    "        # Observation Space: Box(low, high, shape, dtype)\n",
    "        self.observation_space = spaces.Box(\n",
    "            low=-np.inf, high=np.inf, \n",
    "            shape=(self.feature_dim,), \n",
    "            dtype=np.float32\n",
    "        )\n",
    "\n",
    "        self._current_index = 0\n",
    "        self._order = np.arange(self.num_instances)\n",
    "        np.random.shuffle(self._order)\n",
    "\n",
    "    def step(self, action: int):\n",
    "        if self._current_index >= self.num_instances:\n",
    "            return self.observation_space.sample() * 0, 0, True, False, {}\n",
    "\n",
    "        actual_index = self._order[self._current_index]\n",
    "        true_label = self.labels[actual_index]\n",
    "\n",
    "        # Calculate Reward\n",
    "        reward = 0\n",
    "        if action == 1 and true_label == 1:\n",
    "            reward = self.reward_config['TP']\n",
    "        elif action == 1 and true_label == 0:\n",
    "            reward = self.reward_config['FP']\n",
    "        elif action == 0 and true_label == 1:\n",
    "            reward = self.reward_config['FN']\n",
    "        elif action == 0 and true_label == 0:\n",
    "            reward = self.reward_config['TN']\n",
    "\n",
    "        self._current_index += 1\n",
    "        done = self._current_index >= self.num_instances\n",
    "        truncated = False\n",
    "\n",
    "        next_observation = np.zeros(self.feature_dim, dtype=np.float32)\n",
    "        if not done:\n",
    "             next_observation = self.features[self._order[self._current_index]]\n",
    "\n",
    "        info = {\n",
    "            'true_label': true_label,\n",
    "            'predicted_action': action,\n",
    "            'is_done': done\n",
    "        }\n",
    "\n",
    "        return next_observation, reward, done, truncated, info\n",
    "\n",
    "    def reset(self, seed=None, options=None):\n",
    "        super().reset(seed=seed)\n",
    "        self._current_index = 0\n",
    "        self._order = np.arange(self.num_instances)\n",
    "        np.random.shuffle(self._order)\n",
    "        \n",
    "        initial_observation = self.features[self._order[self._current_index]]\n",
    "        return initial_observation, {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Loading and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_creditcard_data(path=\"creditcard.csv\"):\n",
    "    print(\"Loading CreditCard dataset...\")\n",
    "    df = pd.read_csv(path)\n",
    "    \n",
    "    # 1. Balance Data (1:5 Fraud to Non-Fraud)\n",
    "    fraud = df[df['Class'] == 1]\n",
    "    non_fraud = df[df['Class'] == 0]\n",
    "    \n",
    "    # Undersample non-fraud\n",
    "    n_fraud = len(fraud)\n",
    "    n_non_fraud = n_fraud * 5\n",
    "    \n",
    "    if len(non_fraud) > n_non_fraud:\n",
    "        non_fraud = non_fraud.sample(n=n_non_fraud, random_state=SEED)\n",
    "    \n",
    "    balanced_df = pd.concat([fraud, non_fraud]).sample(frac=1, random_state=SEED).reset_index(drop=True)\n",
    "    print(f\"Balanced CreditCard Data: {len(fraud)} Fraud, {len(non_fraud)} Non-Fraud\")\n",
    "\n",
    "    # 2. Split\n",
    "    X = balanced_df.drop('Class', axis=1).values\n",
    "    y = balanced_df['Class'].values\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=SEED, stratify=y)\n",
    "    \n",
    "    # 3. Scale (Fit on Train, Transform Test)\n",
    "    # Scale Time (0) and Amount (29)\n",
    "    def scale_columns(X_tr, X_te, indices):\n",
    "        for i in indices:\n",
    "            scaler_i = StandardScaler()\n",
    "            X_tr[:, i] = scaler_i.fit_transform(X_tr[:, i].reshape(-1, 1)).flatten()\n",
    "            X_te[:, i] = scaler_i.transform(X_te[:, i].reshape(-1, 1)).flatten()\n",
    "        return X_tr, X_te\n",
    "\n",
    "    if X_train.shape[1] == 30:\n",
    "        X_train, X_test = scale_columns(X_train, X_test, [0, 29])\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "def load_paysim_data(path=\"paysim.csv\"):\n",
    "    print(\"Loading PaySim dataset...\")\n",
    "    df = pd.read_csv(path)\n",
    "    \n",
    "    # Drop unnecessary columns\n",
    "    df = df.drop(['nameOrig', 'nameDest', 'isFlaggedFraud'], axis=1)\n",
    "    \n",
    "    # Rename 'isFraud' to 'Class' for consistency\n",
    "    df = df.rename(columns={'isFraud': 'Class'})\n",
    "    \n",
    "    # One-hot encode 'type'\n",
    "    df = pd.get_dummies(df, columns=['type'], drop_first=True)\n",
    "    \n",
    "    # 1. Balance Data (1:5 Fraud to Non-Fraud)\n",
    "    fraud = df[df['Class'] == 1]\n",
    "    non_fraud = df[df['Class'] == 0]\n",
    "    \n",
    "    # Undersample non-fraud\n",
    "    n_fraud = len(fraud)\n",
    "    n_non_fraud = n_fraud * 5\n",
    "    \n",
    "    if len(non_fraud) > n_non_fraud:\n",
    "        non_fraud = non_fraud.sample(n=n_non_fraud, random_state=SEED)\n",
    "        \n",
    "    balanced_df = pd.concat([fraud, non_fraud]).sample(frac=1, random_state=SEED).reset_index(drop=True)\n",
    "    print(f\"Balanced PaySim Data: {len(fraud)} Fraud, {len(non_fraud)} Non-Fraud\")\n",
    "    \n",
    "    # 2. Split\n",
    "    X = balanced_df.drop('Class', axis=1).values.astype(np.float32)\n",
    "    y = balanced_df['Class'].values.astype(np.int64)\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=SEED, stratify=y)\n",
    "    \n",
    "    # 3. Scale\n",
    "    scaler = StandardScaler()\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Preprocessing Techniques (PCA & CTGAN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_pca_ctgan(X_train, y_train, X_test, n_components=0.99, epochs=200):\n",
    "    print(f\"Applying PCA (n_components={n_components}) + CTGAN (epochs={epochs})...\")\n",
    "    \n",
    "    # 1. Apply PCA\n",
    "    pca = PCA(n_components=n_components)\n",
    "    X_train_pca = pca.fit_transform(X_train)\n",
    "    X_test_pca = pca.transform(X_test)\n",
    "    print(f\"PCA reduced dimensions from {X_train.shape[1]} to {X_train_pca.shape[1]}\")\n",
    "    \n",
    "    # 2. Apply CTGAN on PCA-transformed data\n",
    "    # Combine X and y for CTGAN\n",
    "    df_train = pd.DataFrame(X_train_pca, columns=[f'f{i}' for i in range(X_train_pca.shape[1])])\n",
    "    df_train['label'] = y_train\n",
    "    \n",
    "    # Filter fraud samples\n",
    "    fraud_df = df_train[df_train['label'] == 1].drop('label', axis=1)\n",
    "    \n",
    "    if len(fraud_df) == 0:\n",
    "        print(\"No fraud samples found for CTGAN!\")\n",
    "        return X_train_pca, y_train, X_test_pca\n",
    "        \n",
    "    # Train CTGAN\n",
    "    ctgan = CTGAN(epochs=epochs, batch_size=64, pac=1, verbose=True)\n",
    "    ctgan.fit(fraud_df)\n",
    "    \n",
    "    # Generate synthetic samples to balance the dataset (or double the fraud count)\n",
    "    n_synthetic = len(fraud_df) \n",
    "    synthetic_fraud = ctgan.sample(n_synthetic)\n",
    "    \n",
    "    X_synthetic = synthetic_fraud.values\n",
    "    y_synthetic = np.ones(n_synthetic)\n",
    "    \n",
    "    X_aug = np.vstack([X_train_pca, X_synthetic])\n",
    "    y_aug = np.concatenate([y_train, y_synthetic])\n",
    "    \n",
    "    print(f\"Augmented training set from {len(X_train_pca)} to {len(X_aug)} samples.\")\n",
    "    return X_aug, y_aug, X_test_pca\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Experiment Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate(agent_name, X_train, y_train, X_test, y_test, total_timesteps=10000):\n",
    "    # Create Environment\n",
    "    env = DummyVecEnv([lambda: FraudDetectionEnv(X_train, y_train)])\n",
    "    \n",
    "    # Initialize Agent\n",
    "    if agent_name == 'PPO':\n",
    "        # Default PPO parameters as none were specified in reference\n",
    "        model = PPO('MlpPolicy', env, verbose=0)\n",
    "    elif agent_name == 'A2C':\n",
    "        model = A2C(\n",
    "            \"MlpPolicy\",\n",
    "            env,\n",
    "            learning_rate=1e-4,\n",
    "            gamma=0.99,\n",
    "            n_steps=5,\n",
    "            ent_coef=0.01,\n",
    "            vf_coef=0.5,\n",
    "            max_grad_norm=0.5,\n",
    "            verbose=0,\n",
    "            device=\"auto\"\n",
    "        )\n",
    "    elif agent_name == 'DQN':\n",
    "        model = DQN(\n",
    "            \"MlpPolicy\",\n",
    "            env,\n",
    "            learning_rate=linear_schedule(1e-4),\n",
    "            buffer_size=100000,\n",
    "            learning_starts=1000,\n",
    "            batch_size=512,\n",
    "            gamma=0.99,\n",
    "            train_freq=1,\n",
    "            gradient_steps=1,\n",
    "            target_update_interval=500,\n",
    "            exploration_fraction=0.1,\n",
    "            exploration_initial_eps=1.0,\n",
    "            exploration_final_eps=0.05,\n",
    "            max_grad_norm=10,\n",
    "            verbose=0,\n",
    "            device=\"auto\"\n",
    "        )\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown agent: {agent_name}\")\n",
    "    \n",
    "    # Train\n",
    "    model.learn(total_timesteps=total_timesteps)\n",
    "    \n",
    "    # Evaluate\n",
    "    # We'll use the environment logic to step through test set\n",
    "    test_env = FraudDetectionEnv(X_test, y_test)\n",
    "    obs, _ = test_env.reset()\n",
    "    \n",
    "    y_pred = []\n",
    "    y_true = []\n",
    "    \n",
    "    done = False\n",
    "    while not done:\n",
    "        action, _ = model.predict(obs, deterministic=True)\n",
    "        obs, reward, done, truncated, info = test_env.step(action)\n",
    "        \n",
    "        if 'true_label' in info:\n",
    "            y_true.append(info['true_label'])\n",
    "            y_pred.append(action)\n",
    "            \n",
    "    # Metrics\n",
    "    precision = precision_score(y_true, y_pred, zero_division=0)\n",
    "    recall = recall_score(y_true, y_pred, zero_division=0)\n",
    "    f1 = f1_score(y_true, y_pred, zero_division=0)\n",
    "    \n",
    "    return precision, recall, f1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Processing Dataset: CreditCard ===\n",
      "Loading CreditCard dataset...\n",
      "\n",
      "--- Preprocessing: Raw ---\n",
      "Training PPO...\n"
     ]
    }
   ],
   "source": [
    "# Configuration\n",
    "datasets = ['CreditCard', 'PaySim']\n",
    "preprocessing_methods = ['Raw', 'PCA_CTGAN']\n",
    "agents = ['PPO', 'A2C', 'DQN']\n",
    "\n",
    "results = []\n",
    "\n",
    "for dataset_name in datasets:\n",
    "    print(f\"\\n=== Processing Dataset: {dataset_name} ===\")\n",
    "    \n",
    "    # Load Data\n",
    "    if dataset_name == 'CreditCard':\n",
    "        X_train, X_test, y_train, y_test = load_creditcard_data(\"creditcard.csv\")\n",
    "    else:\n",
    "        X_train, X_test, y_train, y_test = load_paysim_data(\"paysim.csv\")\n",
    "        \n",
    "    # Store original copies\n",
    "    X_train_orig, X_test_orig = X_train.copy(), X_test.copy()\n",
    "    y_train_orig = y_train.copy()\n",
    "\n",
    "    for prep in preprocessing_methods:\n",
    "        print(f\"\\n--- Preprocessing: {prep} ---\")\n",
    "        \n",
    "        # Reset data\n",
    "        X_curr_train, X_curr_test = X_train_orig.copy(), X_test_orig.copy()\n",
    "        y_curr_train = y_train_orig.copy()\n",
    "        \n",
    "        # Apply Preprocessing\n",
    "        if prep == 'PCA_CTGAN':\n",
    "            X_curr_train, y_curr_train, X_curr_test = apply_pca_ctgan(X_curr_train, y_curr_train, X_curr_test, epochs=200)\n",
    "            \n",
    "        for agent in agents:\n",
    "            print(f\"Training {agent}...\")\n",
    "            try:\n",
    "                prec, rec, f1 = train_and_evaluate(agent, X_curr_train, y_curr_train, X_curr_test, y_test, total_timesteps=5000)\n",
    "                print(f\"Result: F1={f1:.4f} (Prec={prec:.4f}, Rec={rec:.4f})\")\n",
    "                \n",
    "                results.append({\n",
    "                    'Dataset': dataset_name,\n",
    "                    'Preprocessing': prep,\n",
    "                    'Agent': agent,\n",
    "                    'Precision': prec,\n",
    "                    'Recall': rec,\n",
    "                    'F1': f1\n",
    "                })\n",
    "            except Exception as e:\n",
    "                print(f\"Failed to train {agent}: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Results Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataFrame from results sorted by F1 score\n",
    "results_df = pd.DataFrame(results, columns=['Dataset', 'Agent', 'Preprocessing', 'F1'])\n",
    "sorted_results_df = results_df.sort_values(by='F1', ascending=False)\n",
    "\n",
    "print(\"\\n=== Final Results ===\")\n",
    "print(results_df)\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(14, 6))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.barplot(data=results_df[results_df['Dataset'] == 'CreditCard'], x='Agent', y='F1', hue='Preprocessing')\n",
    "plt.title('CreditCard Dataset - F1 Score')\n",
    "plt.ylim(0, 1)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "sns.barplot(data=results_df[results_df['Dataset'] == 'PaySim'], x='Agent', y='F1', hue='Preprocessing')\n",
    "plt.title('PaySim Dataset - F1 Score')\n",
    "plt.ylim(0, 1)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".pyvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
